{"cells":[{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["[![Open In Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://www.kaggle.com/code/zhnagyuyangyang/build-classic-cnn-and-vit-from-scratch)\n","\n","In this projects, I will build several classfic CNN architecture from scrath, include Vision Transformer. Here are the list:\n","* [VGG](#VGG)\n","* [Res Net](#ResNet)\n","* [Efficient Net](#EfficientNet)\n","* [Mobile Net](#MobileNet)\n","* [Google Net](#GoogleNet)\n","* [Dense Net](#DenseNet)\n","* **[Vision Transformre](#VisionTransformer)**\n","\n","\n","What I have learn through this project:\n","* How to build a complext CNN model\n","* How to adapting the transformer model in computer vision\n","* what is the strength of different CNN architecture "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T13:29:03.269362Z","iopub.status.busy":"2024-03-11T13:29:03.268850Z","iopub.status.idle":"2024-03-11T13:29:03.282139Z","shell.execute_reply":"2024-03-11T13:29:03.280668Z","shell.execute_reply.started":"2024-03-11T13:29:03.269324Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F \n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","import torchvision.datasets as datasets\n","from torchvision import transforms\n","import numpy as np\n","\n","from tqdm.notebook import tqdm, trange\n","import time \n","import random\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T13:16:00.453786Z","iopub.status.busy":"2024-03-11T13:16:00.453374Z","iopub.status.idle":"2024-03-11T13:16:00.466471Z","shell.execute_reply":"2024-03-11T13:16:00.465307Z","shell.execute_reply.started":"2024-03-11T13:16:00.453755Z"},"trusted":true},"outputs":[],"source":["def set_seed(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed(seed)\n","        torch.cuda.manual_seed_all(seed)\n","set_seed(42)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"markdown","metadata":{},"source":["# Prepare DataLoader and training process"]},{"cell_type":"markdown","metadata":{},"source":["## Dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T13:16:00.994352Z","iopub.status.busy":"2024-03-11T13:16:00.993098Z","iopub.status.idle":"2024-03-11T13:16:00.998983Z","shell.execute_reply":"2024-03-11T13:16:00.997902Z","shell.execute_reply.started":"2024-03-11T13:16:00.994316Z"},"trusted":true},"outputs":[],"source":["DATA_PATH = \"./data\"\n","BATCH_SIZE = 128\n","N_EPOCHS = 50"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T13:16:01.207844Z","iopub.status.busy":"2024-03-11T13:16:01.207373Z","iopub.status.idle":"2024-03-11T13:16:03.210683Z","shell.execute_reply":"2024-03-11T13:16:03.209510Z","shell.execute_reply.started":"2024-03-11T13:16:01.207811Z"},"trusted":true},"outputs":[],"source":["test_transforms = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","\n","test_transforms = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","\n","train_dataset =  datasets.CIFAR10(\n","    root=DATA_PATH, \n","    train=True, \n","    download=True, \n","    transform=test_transforms\n",")\n","\n","test_dataset = datasets.CIFAR10(\n","    root=DATA_PATH, \n","    train=False, \n","    download=True, \n","    transform=test_transforms\n",")\n","\n","print(f\"Train Sample Size: {train_dataset.data.shape}\")\n","print(f\"Test Sample Size: {test_dataset.data.shape}\")\n","\n","\n","train_dataloader = DataLoader(\n","    train_dataset, \n","    batch_size=BATCH_SIZE, \n","    shuffle=True,\n","    num_workers=2\n",")\n","\n","test_dataloader = DataLoader(\n","    test_dataset, \n","    batch_size=BATCH_SIZE, \n","    shuffle=True,\n","    num_workers=2\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## Helper functions\n","some helper functions to train and evaluate model, and plot loss and metric"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T13:16:03.215482Z","iopub.status.busy":"2024-03-11T13:16:03.215073Z","iopub.status.idle":"2024-03-11T13:16:03.226986Z","shell.execute_reply":"2024-03-11T13:16:03.225869Z","shell.execute_reply.started":"2024-03-11T13:16:03.215452Z"},"trusted":true},"outputs":[],"source":["def train_one_epoch(\n","    model, \n","    optimizer, \n","    data_loader, \n","    criterion, \n","    metrics, \n","    device\n","):\n","    \"\"\" \n","    Train a model with single epoch, and return the metrics per epoch,  \n","    metrics include:\n","        - loss \n","        - accuracy\n","    \"\"\"\n","    print(\"Training...\")\n","    summ = []\n","    \n","    model.train()\n","    with tqdm(total=len(data_loader)) as t:\n","        for i, (X_train, y_train) in enumerate(data_loader):\n","            X_train, y_train = X_train.to(device), y_train.to(device)\n","            \n","            y_pred = model(X_train)\n","            loss = criterion(y_pred, y_train)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            \n","            y_pred = y_pred.data.cpu().numpy()\n","            y_train = y_train.data.cpu().numpy()\n","            \n","            summary_batch = {\n","                metric: metrics[metric](y_pred, y_train) for metric in metrics\n","            }\n","            \n","            summary_batch['loss'] = loss.item()\n","            \n","            summ.append(summary_batch)\n","        \n","            t.set_postfix(accuracy = \"{:05.3f}\".format(summary_batch['accuracy']), loss=\"{:05.3f}\".format(loss.item()))\n","            t.update()\n","\n","    metrics_mean = {\n","        metric: np.mean([x[metric] for x in summ]) for metric in summ[0]\n","    }\n","    \n","    return metrics_mean"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T13:16:03.229044Z","iopub.status.busy":"2024-03-11T13:16:03.228100Z","iopub.status.idle":"2024-03-11T13:16:03.249299Z","shell.execute_reply":"2024-03-11T13:16:03.248257Z","shell.execute_reply.started":"2024-03-11T13:16:03.229013Z"},"trusted":true},"outputs":[],"source":["def evaluate(model, data_loader, criterion, metrics, device):\n","    print(\"Evaluating...\")\n","    model.eval()\n","    \n","    summ = []\n","    with tqdm(total=len(data_loader)) as t:\n","        for i, (X_test, y_test) in enumerate(data_loader):\n","            X_test, y_test = X_test.to(device), y_test.to(device)\n","\n","            y_pred = model(X_test)\n","            loss = criterion(y_pred, y_test)\n","\n","\n","            y_pred = y_pred.data.cpu().numpy()\n","            y_test = y_test.data.cpu().numpy()\n","\n","            summary_batch = {\n","                metric: metrics[metric](y_pred, y_test) for metric in metrics\n","            }\n","            summary_batch['loss'] = loss.item()\n","\n","            summ.append(summary_batch)\n","\n","            t.set_postfix(accuracy = \"{:05.3f}\".format(summary_batch['accuracy']), loss=\"{:05.3f}\".format(loss.item()))\n","            t.update()\n","    \n","    metrics_mean = {\n","        metric: np.mean([x[metric] for x in summ]) for metric in summ[0]\n","    }\n","\n","    return metrics_mean"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T13:16:03.252461Z","iopub.status.busy":"2024-03-11T13:16:03.252048Z","iopub.status.idle":"2024-03-11T13:16:03.267564Z","shell.execute_reply":"2024-03-11T13:16:03.266086Z","shell.execute_reply.started":"2024-03-11T13:16:03.252429Z"},"trusted":true},"outputs":[],"source":["def train(\n","    model, \n","    train_dataloader, \n","    test_dataloader, \n","    optimizer, \n","    criterion, \n","    metrics, \n","    num_epochs, \n","    device,\n","    scheduler = None,\n","):\n","\n","    summ = {'train': {}, 'val': {}}\n","    best_val_acc = 0.0 \n","    \n","    model.to(device)\n","\n","    \n","    for epoch in range(num_epochs):\n","        print(f\"Epoch {epoch + 1} / {num_epochs}\")\n","        train_metrics = train_one_epoch(\n","            model = model,\n","            data_loader=train_dataloader,\n","            optimizer=optimizer,\n","            criterion=criterion,\n","            metrics=metrics,\n","            device = device,\n","        )\n","        eval_metrics = evaluate(\n","            model=model,\n","            data_loader=test_dataloader,\n","            criterion=criterion,\n","            metrics=metrics,\n","            device = device\n","        )\n","        summ['train'][epoch + 1] =  train_metrics\n","        summ['val'][epoch + 1] =  eval_metrics\n","        if scheduler:\n","            scheduler.step()\n","    \n","    return summ"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T13:16:03.269450Z","iopub.status.busy":"2024-03-11T13:16:03.269037Z","iopub.status.idle":"2024-03-11T13:16:03.278659Z","shell.execute_reply":"2024-03-11T13:16:03.277332Z","shell.execute_reply.started":"2024-03-11T13:16:03.269416Z"},"trusted":true},"outputs":[],"source":["def accuracy(outputs, labels):\n","    \"\"\" \n","    outputs size: (B, 10) 10 is the number of classes\n","    labels size: (B, )\n","    \"\"\"\n","    # (B, 10) -> (B, )\n","    outputs = np.argmax(outputs, axis=1)\n","    return np.sum(outputs == labels) / float(labels.size)\n","\n","metrics = {\n","    \"accuracy\": accuracy\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T13:16:03.281465Z","iopub.status.busy":"2024-03-11T13:16:03.280041Z","iopub.status.idle":"2024-03-11T13:16:03.295401Z","shell.execute_reply":"2024-03-11T13:16:03.294302Z","shell.execute_reply.started":"2024-03-11T13:16:03.281417Z"},"trusted":true},"outputs":[],"source":["def plot_one_model_summ(data):\n","    \"\"\" \n","    summ is like: \n","    {\n","        \"train\": {\n","            1: {\"accuracy\": ,\"loss\": }\n","        }\n","    }\n","    \"\"\"\n","    # Extracting values for plotting\n","    epochs = list(data['train'].keys())\n","    train_accuracy = [data['train'][epoch]['accuracy'] for epoch in epochs]\n","    val_accuracy = [data['val'][epoch]['accuracy'] for epoch in epochs]\n","    train_loss = [data['train'][epoch]['loss'] for epoch in epochs]\n","    val_loss = [data['val'][epoch]['loss'] for epoch in epochs]\n","\n","    # Plotting\n","    plt.figure(figsize=(12, 6))\n","\n","    # Accuracy plot\n","    plt.subplot(1, 2, 1)\n","    plt.plot(epochs, train_accuracy, label='Train Accuracy')\n","    plt.plot(epochs, val_accuracy, label='Validation Accuracy')\n","    plt.title('Training and Validation Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","\n","    # Loss plot\n","    plt.subplot(1, 2, 2)\n","    plt.plot(epochs, train_loss, label='Train Loss')\n","    plt.plot(epochs, val_loss, label='Validation Loss')\n","    plt.title('Training and Validation Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def train_model(model: nn.Module, EPOCHS):\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.SGD(\n","        model.parameters(), \n","        lr=0.1,\n","        momentum=0.9, \n","        weight_decay=5e-4\n","    )\n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n","    start_time = time.time()\n","    \n","    summ = train(\n","        model = model,\n","        criterion = criterion, \n","        optimizer = optimizer,\n","        train_dataloader = train_dataloader,\n","        test_dataloader = test_dataloader, \n","        num_epochs = EPOCHS,\n","        metrics = metrics,\n","        device = device,\n","        scheduler = scheduler\n","    )\n","    total_time = (time.time() - start_time)\n","    \n","    print(\"Total time to train model: {:.2f}s\".format(total_time))\n","    print(f\"Final accuracy on train datasets: {summ['train'][EPOCHS]['accuracy']}\")\n","    print(f\"Final accuracy on test datasets: {summ['val'][EPOCHS]['accuracy']}\")\n","    \n","    plot_one_model_summ(summ)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Test above functions \n","\n","class mlp(nn.Module):\n","    def __init__(\n","        self,\n","        input_size = 3*32*32,\n","        output_size = 10,\n","    ):\n","        super().__init__()\n","        self.layers = nn.Sequential(\n","            nn.Linear(input_size, 128),\n","            nn.Linear(128, 10)\n","        )\n","    \n","    def forward(self, x):\n","        batches = x.shape[0]\n","        x = x.view(batches, -1) # flatten\n","        out = self.layers(x)\n","        return F.log_softmax(out, dim=-1)\n","    \n","model = mlp()\n","train_model(model, 2)"]},{"cell_type":"markdown","metadata":{},"source":["# VGG"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cfg = {\n","    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n","    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n","    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n","    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T12:27:09.846313Z","iopub.status.busy":"2024-03-11T12:27:09.845895Z","iopub.status.idle":"2024-03-11T12:27:09.857527Z","shell.execute_reply":"2024-03-11T12:27:09.856216Z","shell.execute_reply.started":"2024-03-11T12:27:09.846282Z"},"trusted":true},"outputs":[],"source":["class VGG(nn.Module):\n","    def __init__(self, vgg_name):\n","        super().__init__()\n","        self.features = self._make_layers(cfg[vgg_name])\n","        self.classifier = nn.Linear(512, 10)\n","    \n","    def _make_layers(self, cfg):\n","        layers = []\n","        in_channels = 3\n","        for x in cfg:\n","            if x == 'M':\n","                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n","            else:\n","                layer += [\n","                    nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n","                    nn.BatchNorm2d(x),\n","                    nn.ReLU(inplace=True)\n","                         ]\n","        layers += [nn.AvgPool2d(kernel_size = 1, stride=1)]\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = self.features(x)\n","        # Flatten\n","        out = out.view(out.size(0), -1)\n","        out = self.classifier(out)\n","        return out "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["vgg_model = VGG('VGG19')\n","\n","train_model(vgg_model, N_EPOCHS)"]},{"cell_type":"markdown","metadata":{},"source":["# Resnet"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T12:06:36.389422Z","iopub.status.busy":"2024-03-11T12:06:36.388968Z","iopub.status.idle":"2024-03-11T12:06:36.401212Z","shell.execute_reply":"2024-03-11T12:06:36.399826Z","shell.execute_reply.started":"2024-03-11T12:06:36.389387Z"},"trusted":true},"outputs":[],"source":["class BasicBlock(nn.Module):\n","    expansion = 1 \n","    def __init__(\n","        self,\n","        in_planes,\n","        planes,\n","        stride=1\n","    ):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(\n","            in_planes, planes, kernel_size = 3, stride= stride,padding=1, bias=False\n","        )\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion * planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=1, bias=False),\n","                nn.BatchNorm2d(self.expansion * planes)\n","            )\n","        \n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T12:10:50.045448Z","iopub.status.busy":"2024-03-11T12:10:50.045037Z","iopub.status.idle":"2024-03-11T12:10:50.058012Z","shell.execute_reply":"2024-03-11T12:10:50.056688Z","shell.execute_reply.started":"2024-03-11T12:10:50.045416Z"},"trusted":true},"outputs":[],"source":["class Bottleneck(nn.Module):\n","    expansion = 4 \n","    \n","    def __init__(self, in_planes, planes, stride=1):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size = 3, stride=stride, padding=1, biasd=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion * planes, kernel_size = 1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.exansion * planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion * planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.exansion * planes, kernel_size = 1, stride = stride, bias = False),\n","                nn.BatchNorm2d(self.exansion * planes)\n","            )\n","            \n","        \n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super().__init__()\n","        self.in_planes = 64\n","        \n","        self.conv1 = nn.Conv2d(3, 64, kernel_size = 3, stride=1, padding=1, bias = False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","    \n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1] * (num_blocks - 1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        \n","        return nn.Sequential(*layers)\n","    \n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","    \n","    \n","def ResNet18():\n","    return ResNet(BasicBlock, [2,2,2,2])\n","\n","def ResNet34():\n","    return ResNet(BasicBlock, [3, 4, 6, 3])\n","\n","\n","def ResNet50():\n","    return ResNet(Bottleneck, [3, 4, 6, 3])\n","\n","\n","def ResNet101():\n","    return ResNet(Bottleneck, [3, 4, 23, 3])\n","\n","\n","def ResNet152():\n","    return ResNet(Bottleneck, [3, 8, 36, 3])\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["res_model = ResNet152()\n","train_model(res_model, N_EPOCHS)"]},{"cell_type":"markdown","metadata":{},"source":["# EfficientNet"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T12:29:10.359476Z","iopub.status.busy":"2024-03-11T12:29:10.358999Z","iopub.status.idle":"2024-03-11T12:29:10.366914Z","shell.execute_reply":"2024-03-11T12:29:10.366022Z","shell.execute_reply.started":"2024-03-11T12:29:10.359440Z"},"trusted":true},"outputs":[],"source":["def swish(x):\n","    return x * x.sigmoid()\n","\n","def drop_connect(x, drop_ratio):\n","    keep_ratio = 1.0 - drop_ratio\n","    mask = torch.empty([x.shape[0], 1, 1, 1], dtype=x.dtype, device=x.device)\n","    mask.bernouli_(keep_ratio)\n","    x.div_(keep_ratio)\n","    x.mul(mask)\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T12:30:38.683685Z","iopub.status.busy":"2024-03-11T12:30:38.683278Z","iopub.status.idle":"2024-03-11T12:30:38.692614Z","shell.execute_reply":"2024-03-11T12:30:38.690687Z","shell.execute_reply.started":"2024-03-11T12:30:38.683655Z"},"trusted":true},"outputs":[],"source":["class SE(nn.Module):\n","    def __init__(self, in_channels, se_channels):\n","        super().__init__()\n","        self.se1 = nn.Conv2d(in_channels, se_channels, kernel_size = 1,bias=True)\n","        self.se2 = nn.Conv2d(se_channels, in_channels, kernel_size = 1, bias=True)\n","    \n","    \n","    def forward(self, x):\n","        out = F.adaptive_avg_pool2d(x, (1,1))\n","        out = swish(self.se1(out))\n","        out = self.se2(out).sigmoid()\n","        out = x * out \n","        return out "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T12:35:55.994126Z","iopub.status.busy":"2024-03-11T12:35:55.993750Z","iopub.status.idle":"2024-03-11T12:35:56.008887Z","shell.execute_reply":"2024-03-11T12:35:56.007465Z","shell.execute_reply.started":"2024-03-11T12:35:55.994098Z"},"trusted":true},"outputs":[],"source":["class Block(nn.Module):\n","    def __init__(\n","        self,\n","        in_channels,\n","        out_channels,\n","        kernel_size,\n","        stride,\n","        expand_ratio=1,\n","        se_ratio=0.,\n","        drop_rate=0.\n","    ):\n","        super().__init__()\n","        self.stride = stride \n","        self.drop_rat = drop_rate \n","        self.expand_ratio = expand_ratio \n","        \n","        # Expansion \n","        channels = expand_ratio * in_channels \n","        self.conv1 = nn.Conv2d(\n","            in_channels, \n","            channels,\n","            kernel_size = 1,\n","            stride = 1,\n","            padding = 0,\n","            bias = False \n","        )\n","        self.bn1 = nn.BatchNorm2d(channels)\n","        \n","        # Dethwise conv\n","        self.conv2 = nn.Conv2d(\n","            channels,\n","            channels,\n","            kernel_size = kernel_size,\n","            stride = stride,\n","            padding = (1 if kernel_size == 3 else 2),\n","            groups = channels,\n","            bias = False \n","        )\n","        self.bn2 = nn.BatchNorm2d(channels)\n","        \n","        # SE layers \n","        se_channels = int(in_channels * se_ratio)\n","        self.se = SE(channels, se_channels)\n","        \n","        # Output\n","        self.conv3 = nn.Conv2d(\n","            channels,\n","            out_channels,\n","            kernel_size = 1,\n","            stride = 1,\n","            padding = 0,\n","            bias = False\n","        )\n","        \n","        self.bn3 = nn.BatchNorm2d(out_channels)\n","        self.has_skip = (stride == 1) and (in_channels == out_channels)\n","        \n","    \n","    def forward(self, x):\n","        out = x if self.expand_ratio == 1 else swish(self.bn1(self.conv1(x)))\n","        out = swish(self.bn2(self.conv2(out)))\n","        out = self.se(out)\n","        out = self.bn3(self.conv3(out))\n","        if self.has_skip:\n","            if self.training and self.drop_rate > 0:\n","                out = drop_connect(out, self.drop_rate)\n","            out = out + x\n","        return out\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T12:36:52.250311Z","iopub.status.busy":"2024-03-11T12:36:52.249822Z","iopub.status.idle":"2024-03-11T12:36:52.264799Z","shell.execute_reply":"2024-03-11T12:36:52.263882Z","shell.execute_reply.started":"2024-03-11T12:36:52.250245Z"},"trusted":true},"outputs":[],"source":["class EfficientNet(nn.Module):\n","    def __init__(self, cfg, num_classes=10):\n","        super(EfficientNet, self).__init__()\n","        self.cfg = cfg\n","        self.conv1 = nn.Conv2d(3,\n","                               32,\n","                               kernel_size=3,\n","                               stride=1,\n","                               padding=1,\n","                               bias=False)\n","        self.bn1 = nn.BatchNorm2d(32)\n","        self.layers = self._make_layers(in_channels=32)\n","        self.linear = nn.Linear(cfg['out_channels'][-1], num_classes)\n","\n","    def _make_layers(self, in_channels):\n","        layers = []\n","        cfg = [self.cfg[k] for k in ['expansion', 'out_channels', 'num_blocks', 'kernel_size',\n","                                     'stride']]\n","        b = 0\n","        blocks = sum(self.cfg['num_blocks'])\n","        for expansion, out_channels, num_blocks, kernel_size, stride in zip(*cfg):\n","            strides = [stride] + [1] * (num_blocks - 1)\n","            for stride in strides:\n","                drop_rate = self.cfg['drop_connect_rate'] * b / blocks\n","                layers.append(\n","                    Block(in_channels,\n","                          out_channels,\n","                          kernel_size,\n","                          stride,\n","                          expansion,\n","                          se_ratio=0.25,\n","                          drop_rate=drop_rate))\n","                in_channels = out_channels\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = swish(self.bn1(self.conv1(x)))\n","        out = self.layers(out)\n","        out = F.adaptive_avg_pool2d(out, 1)\n","        out = out.view(out.size(0), -1)\n","        dropout_rate = self.cfg['dropout_rate']\n","        if self.training and dropout_rate > 0:\n","            out = F.dropout(out, p=dropout_rate)\n","        out = self.linear(out)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T12:36:59.498857Z","iopub.status.busy":"2024-03-11T12:36:59.498447Z","iopub.status.idle":"2024-03-11T12:36:59.506915Z","shell.execute_reply":"2024-03-11T12:36:59.505465Z","shell.execute_reply.started":"2024-03-11T12:36:59.498827Z"},"trusted":true},"outputs":[],"source":["def EfficientNetB0():\n","    cfg = {\n","        'num_blocks': [1, 2, 2, 3, 3, 4, 1],\n","        'expansion': [1, 6, 6, 6, 6, 6, 6],\n","        'out_channels': [16, 24, 40, 80, 112, 192, 320],\n","        'kernel_size': [3, 3, 5, 3, 5, 5, 3],\n","        'stride': [1, 2, 2, 2, 1, 2, 1],\n","        'dropout_rate': 0.2,\n","        'drop_connect_rate': 0.2,\n","    }\n","    return EfficientNet(cfg)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["eff_net = EfficientNetB0()\n","\n","train_model(eff_net)"]},{"cell_type":"markdown","metadata":{},"source":["# MobileNet"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T12:37:44.668808Z","iopub.status.busy":"2024-03-11T12:37:44.666951Z","iopub.status.idle":"2024-03-11T12:37:44.680241Z","shell.execute_reply":"2024-03-11T12:37:44.678907Z","shell.execute_reply.started":"2024-03-11T12:37:44.668763Z"},"trusted":true},"outputs":[],"source":["class Block(nn.Module):\n","    '''Depthwise conv + Pointwise conv'''\n","    def __init__(self, in_planes, out_planes, stride=1):\n","        super(Block, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, in_planes, kernel_size=3, stride=stride, padding=1, groups=in_planes, bias=False)\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.conv2 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_planes)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T12:37:51.784068Z","iopub.status.busy":"2024-03-11T12:37:51.783660Z","iopub.status.idle":"2024-03-11T12:37:51.797201Z","shell.execute_reply":"2024-03-11T12:37:51.795673Z","shell.execute_reply.started":"2024-03-11T12:37:51.784037Z"},"trusted":true},"outputs":[],"source":["class MobileNet(nn.Module):\n","    # (128,2) means conv planes=128, conv stride=2, by default conv stride=1\n","    cfg = [64, (128,2), 128, (256,2), 256, (512,2), 512, 512, 512, 512, 512, (1024,2), 1024]\n","\n","    def __init__(self, num_classes=10):\n","        super(MobileNet, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(32)\n","        self.layers = self._make_layers(in_planes=32)\n","        self.linear = nn.Linear(1024, num_classes)\n","\n","    def _make_layers(self, in_planes):\n","        layers = []\n","        for x in self.cfg:\n","            out_planes = x if isinstance(x, int) else x[0]\n","            stride = 1 if isinstance(x, int) else x[1]\n","            layers.append(Block(in_planes, out_planes, stride))\n","            in_planes = out_planes\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layers(out)\n","        out = F.avg_pool2d(out, 2)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mobile_net = MobileNet()\n","train_model(mobile_net)"]},{"cell_type":"markdown","metadata":{},"source":["# GoogleNet"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T12:38:17.604594Z","iopub.status.busy":"2024-03-11T12:38:17.604190Z","iopub.status.idle":"2024-03-11T12:38:17.617533Z","shell.execute_reply":"2024-03-11T12:38:17.616663Z","shell.execute_reply.started":"2024-03-11T12:38:17.604565Z"},"trusted":true},"outputs":[],"source":["class Inception(nn.Module):\n","    def __init__(self, in_planes, n1x1, n3x3red, n3x3, n5x5red, n5x5, pool_planes):\n","        super(Inception, self).__init__()\n","        # 1x1 conv branch\n","        self.b1 = nn.Sequential(\n","            nn.Conv2d(in_planes, n1x1, kernel_size=1),\n","            nn.BatchNorm2d(n1x1),\n","            nn.ReLU(True),\n","        )\n","\n","        # 1x1 conv -> 3x3 conv branch\n","        self.b2 = nn.Sequential(\n","            nn.Conv2d(in_planes, n3x3red, kernel_size=1),\n","            nn.BatchNorm2d(n3x3red),\n","            nn.ReLU(True),\n","            nn.Conv2d(n3x3red, n3x3, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(n3x3),\n","            nn.ReLU(True),\n","        )\n","\n","        # 1x1 conv -> 5x5 conv branch\n","        self.b3 = nn.Sequential(\n","            nn.Conv2d(in_planes, n5x5red, kernel_size=1),\n","            nn.BatchNorm2d(n5x5red),\n","            nn.ReLU(True),\n","            nn.Conv2d(n5x5red, n5x5, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(n5x5),\n","            nn.ReLU(True),\n","            nn.Conv2d(n5x5, n5x5, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(n5x5),\n","            nn.ReLU(True),\n","        )\n","\n","        # 3x3 pool -> 1x1 conv branch\n","        self.b4 = nn.Sequential(\n","            nn.MaxPool2d(3, stride=1, padding=1),\n","            nn.Conv2d(in_planes, pool_planes, kernel_size=1),\n","            nn.BatchNorm2d(pool_planes),\n","            nn.ReLU(True),\n","        )\n","\n","    def forward(self, x):\n","        y1 = self.b1(x)\n","        y2 = self.b2(x)\n","        y3 = self.b3(x)\n","        y4 = self.b4(x)\n","        return torch.cat([y1,y2,y3,y4], 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T12:38:24.304726Z","iopub.status.busy":"2024-03-11T12:38:24.304324Z","iopub.status.idle":"2024-03-11T12:38:24.322497Z","shell.execute_reply":"2024-03-11T12:38:24.321359Z","shell.execute_reply.started":"2024-03-11T12:38:24.304697Z"},"trusted":true},"outputs":[],"source":["class GoogLeNet(nn.Module):\n","    def __init__(self):\n","        super(GoogLeNet, self).__init__()\n","        self.pre_layers = nn.Sequential(\n","            nn.Conv2d(3, 192, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(192),\n","            nn.ReLU(True),\n","        )\n","\n","        self.a3 = Inception(192,  64,  96, 128, 16, 32, 32)\n","        self.b3 = Inception(256, 128, 128, 192, 32, 96, 64)\n","\n","        self.maxpool = nn.MaxPool2d(3, stride=2, padding=1)\n","\n","        self.a4 = Inception(480, 192,  96, 208, 16,  48,  64)\n","        self.b4 = Inception(512, 160, 112, 224, 24,  64,  64)\n","        self.c4 = Inception(512, 128, 128, 256, 24,  64,  64)\n","        self.d4 = Inception(512, 112, 144, 288, 32,  64,  64)\n","        self.e4 = Inception(528, 256, 160, 320, 32, 128, 128)\n","\n","        self.a5 = Inception(832, 256, 160, 320, 32, 128, 128)\n","        self.b5 = Inception(832, 384, 192, 384, 48, 128, 128)\n","\n","        self.avgpool = nn.AvgPool2d(8, stride=1)\n","        self.linear = nn.Linear(1024, 10)\n","\n","    def forward(self, x):\n","        out = self.pre_layers(x)\n","        out = self.a3(out)\n","        out = self.b3(out)\n","        out = self.maxpool(out)\n","        out = self.a4(out)\n","        out = self.b4(out)\n","        out = self.c4(out)\n","        out = self.d4(out)\n","        out = self.e4(out)\n","        out = self.maxpool(out)\n","        out = self.a5(out)\n","        out = self.b5(out)\n","        out = self.avgpool(out)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["google_net = GoogLeNet()\n","\n","train_model(google_net)"]},{"cell_type":"markdown","metadata":{},"source":["# DenseNet"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T12:38:50.949962Z","iopub.status.busy":"2024-03-11T12:38:50.949552Z","iopub.status.idle":"2024-03-11T12:38:50.958368Z","shell.execute_reply":"2024-03-11T12:38:50.957499Z","shell.execute_reply.started":"2024-03-11T12:38:50.949933Z"},"trusted":true},"outputs":[],"source":["class Bottleneck(nn.Module):\n","    def __init__(self, in_planes, growth_rate):\n","        super(Bottleneck, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_planes)\n","        self.conv1 = nn.Conv2d(in_planes, 4*growth_rate, kernel_size=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(4*growth_rate)\n","        self.conv2 = nn.Conv2d(4*growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\n","\n","    def forward(self, x):\n","        out = self.conv1(F.relu(self.bn1(x)))\n","        out = self.conv2(F.relu(self.bn2(out)))\n","        out = torch.cat([out,x], 1)\n","        return out\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T12:38:55.279461Z","iopub.status.busy":"2024-03-11T12:38:55.279033Z","iopub.status.idle":"2024-03-11T12:38:55.287231Z","shell.execute_reply":"2024-03-11T12:38:55.285970Z","shell.execute_reply.started":"2024-03-11T12:38:55.279429Z"},"trusted":true},"outputs":[],"source":["class Transition(nn.Module):\n","    def __init__(self, in_planes, out_planes):\n","        super(Transition, self).__init__()\n","        self.bn = nn.BatchNorm2d(in_planes)\n","        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=1, bias=False)\n","\n","    def forward(self, x):\n","        out = self.conv(F.relu(self.bn(x)))\n","        out = F.avg_pool2d(out, 2)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-11T12:39:02.885378Z","iopub.status.busy":"2024-03-11T12:39:02.884959Z","iopub.status.idle":"2024-03-11T12:39:02.905183Z","shell.execute_reply":"2024-03-11T12:39:02.903698Z","shell.execute_reply.started":"2024-03-11T12:39:02.885346Z"},"trusted":true},"outputs":[],"source":["class DenseNet(nn.Module):\n","    def __init__(self, block, nblocks, growth_rate=12, reduction=0.5, num_classes=10):\n","        super(DenseNet, self).__init__()\n","        self.growth_rate = growth_rate\n","\n","        num_planes = 2*growth_rate\n","        self.conv1 = nn.Conv2d(3, num_planes, kernel_size=3, padding=1, bias=False)\n","\n","        self.dense1 = self._make_dense_layers(block, num_planes, nblocks[0])\n","        num_planes += nblocks[0]*growth_rate\n","        out_planes = int(math.floor(num_planes*reduction))\n","        self.trans1 = Transition(num_planes, out_planes)\n","        num_planes = out_planes\n","\n","        self.dense2 = self._make_dense_layers(block, num_planes, nblocks[1])\n","        num_planes += nblocks[1]*growth_rate\n","        out_planes = int(math.floor(num_planes*reduction))\n","        self.trans2 = Transition(num_planes, out_planes)\n","        num_planes = out_planes\n","\n","        self.dense3 = self._make_dense_layers(block, num_planes, nblocks[2])\n","        num_planes += nblocks[2]*growth_rate\n","        out_planes = int(math.floor(num_planes*reduction))\n","        self.trans3 = Transition(num_planes, out_planes)\n","        num_planes = out_planes\n","\n","        self.dense4 = self._make_dense_layers(block, num_planes, nblocks[3])\n","        num_planes += nblocks[3]*growth_rate\n","\n","        self.bn = nn.BatchNorm2d(num_planes)\n","        self.linear = nn.Linear(num_planes, num_classes)\n","\n","    def _make_dense_layers(self, block, in_planes, nblock):\n","        layers = []\n","        for i in range(nblock):\n","            layers.append(block(in_planes, self.growth_rate))\n","            in_planes += self.growth_rate\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = self.conv1(x)\n","        out = self.trans1(self.dense1(out))\n","        out = self.trans2(self.dense2(out))\n","        out = self.trans3(self.dense3(out))\n","        out = self.dense4(out)\n","        out = F.avg_pool2d(F.relu(self.bn(out)), 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","\n","def DenseNet121():\n","    return DenseNet(Bottleneck, [6,12,24,16], growth_rate=32)\n","\n","def DenseNet169():\n","    return DenseNet(Bottleneck, [6,12,32,32], growth_rate=32)\n","\n","def DenseNet201():\n","    return DenseNet(Bottleneck, [6,12,48,32], growth_rate=32)\n","\n","def DenseNet161():\n","    return DenseNet(Bottleneck, [6,12,36,24], growth_rate=48)\n","\n","def densenet_cifar():\n","    return DenseNet(Bottleneck, [6,12,24,16], growth_rate=12)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dense_net = densenet_cifar()\n","\n","train_model(dense_net)"]},{"cell_type":"markdown","metadata":{},"source":["# VisionTransformer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30664,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
